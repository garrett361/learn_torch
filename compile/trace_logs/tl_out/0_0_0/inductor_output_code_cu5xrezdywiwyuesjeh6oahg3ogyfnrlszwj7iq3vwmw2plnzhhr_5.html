<pre style="background-color:#ffffff;">
<span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">ctypes </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">c_void_p, c_long
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">torch
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">math
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">random
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">os
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">tempfile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">math </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">inf, nan
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.hooks </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">run_intermediate_hooks
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">maybe_profile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.memory_planning </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">_align </span><span style="font-weight:bold;color:#a71d5d;">as </span><span style="color:#323232;">align
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">device, empty_strided
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codecache </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">AsyncCompile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.select_algorithm </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">extern_kernels
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.multi_kernel </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">MultiKernelCall
</span><span style="color:#323232;">
</span><span style="color:#323232;">aten </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.aten
</span><span style="color:#323232;">inductor_ops </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor
</span><span style="color:#323232;">assert_size_stride </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards.assert_size_stride
</span><span style="color:#323232;">empty_strided_cpu </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cpu
</span><span style="color:#323232;">empty_strided_cuda </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cuda
</span><span style="color:#323232;">alloc_from_pool </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor._alloc_from_pool
</span><span style="color:#323232;">reinterpret_tensor </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor._reinterpret_tensor
</span><span style="color:#323232;">async_compile </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">AsyncCompile()
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-style:italic;color:#969896;"># kernel path: /tmp/torchinductor_goon/hh/chhow3e2ads6inioqv6rtikm32cbrfpypw4vdc3rh7hyck3nwv3e.py
</span><span style="font-style:italic;color:#969896;"># Source Nodes: [relu], Original ATen: [aten.relu]
</span><span style="font-style:italic;color:#969896;"># relu =&gt; relu
</span><span style="color:#323232;">triton_poi_fused_relu_0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.triton(</span><span style="color:#183691;">&#39;triton_&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">import triton
</span><span style="color:#183691;">import triton.language as tl
</span><span style="color:#183691;">from triton.compiler.compiler import AttrsDescriptor
</span><span style="color:#183691;">
</span><span style="color:#183691;">from torch._inductor import triton_helpers, triton_heuristics
</span><span style="color:#183691;">from torch._inductor.ir import ReductionHint, TileHint
</span><span style="color:#183691;">from torch._inductor.triton_helpers import libdevice, math as tl_math
</span><span style="color:#183691;">from torch._inductor.triton_heuristics import AutotuneHint
</span><span style="color:#183691;">from torch._inductor.utils import instance_descriptor
</span><span style="color:#183691;">
</span><span style="color:#183691;">@triton_heuristics.pointwise(
</span><span style="color:#183691;">    size_hints=[128], 
</span><span style="color:#183691;">    filename=__file__,
</span><span style="color:#183691;">    triton_meta={&#39;signature&#39;: {0: &#39;*fp32&#39;, 1: &#39;i32&#39;}, &#39;device&#39;: 0, &#39;device_type&#39;: &#39;cuda&#39;, &#39;constants&#39;: </span><span style="color:#0086b3;">{}</span><span style="color:#183691;">, &#39;configs&#39;: [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(1,))]},
</span><span style="color:#183691;">    inductor_meta={&#39;autotune_hints&#39;: set(), &#39;kernel_name&#39;: &#39;triton_poi_fused_relu_0&#39;, &#39;mutated_arg_names&#39;: [&#39;in_out_ptr0&#39;], &#39;no_x_dim&#39;: False, &#39;backend_hash&#39;: &#39;493e1fe457c358ce90acff64111ef5f4d47f6118d8ea0b6619574e4de66e314f&#39;},
</span><span style="color:#183691;">    min_elem_per_thread=0
</span><span style="color:#183691;">)
</span><span style="color:#183691;">@triton.jit
</span><span style="color:#183691;">def triton_(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
</span><span style="color:#183691;">    xnumel = 128
</span><span style="color:#183691;">    xoffset = tl.program_id(0) * XBLOCK
</span><span style="color:#183691;">    xindex = xoffset + tl.arange(0, XBLOCK)[:]
</span><span style="color:#183691;">    xmask = xindex &lt; xnumel
</span><span style="color:#183691;">    x0 = xindex
</span><span style="color:#183691;">    tmp0 = tl.load(in_out_ptr0 + (x0), xmask)
</span><span style="color:#183691;">    tmp1 = triton_helpers.maximum(0, tmp0)
</span><span style="color:#183691;">    tl.store(in_out_ptr0 + (x0), tmp1, xmask)
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">, device_str</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cuda&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">triton
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">triton.language </span><span style="font-weight:bold;color:#a71d5d;">as </span><span style="color:#323232;">tl
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.triton_heuristics </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">grid, split_scan_grid, start_graph, end_graph
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._C </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">_cuda_getCurrentRawStream </span><span style="font-weight:bold;color:#a71d5d;">as </span><span style="color:#323232;">get_raw_stream
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">async_compile.wait(</span><span style="color:#62a35c;">globals</span><span style="color:#323232;">())
</span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">async_compile
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">call</span><span style="color:#323232;">(args):
</span><span style="color:#323232;">    primals_1, primals_2, primals_3 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">args
</span><span style="color:#323232;">    args.clear()
</span><span style="color:#323232;">    assert_size_stride(primals_1, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_2, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_3, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">with </span><span style="color:#323232;">torch.cuda._DeviceGuard(</span><span style="color:#0086b3;">0</span><span style="color:#323232;">):
</span><span style="color:#323232;">        torch.cuda.set_device(</span><span style="color:#0086b3;">0</span><span style="color:#323232;">)
</span><span style="color:#323232;">        buf0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cuda((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">        </span><span style="font-style:italic;color:#969896;"># Source Nodes: [l__self___lin0], Original ATen: [aten.mm]
</span><span style="color:#323232;">        extern_kernels.mm(primals_3, reinterpret_tensor(primals_1, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf0)
</span><span style="color:#323232;">        </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_1
</span><span style="color:#323232;">        buf1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf0; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf0  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">        </span><span style="font-style:italic;color:#969896;"># Source Nodes: [relu], Original ATen: [aten.relu]
</span><span style="color:#323232;">        stream0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">get_raw_stream(</span><span style="color:#0086b3;">0</span><span style="color:#323232;">)
</span><span style="color:#323232;">        triton_poi_fused_relu_0.run(buf1, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, grid</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">grid(</span><span style="color:#0086b3;">128</span><span style="color:#323232;">), stream</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">stream0)
</span><span style="color:#323232;">        buf2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cuda((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">        </span><span style="font-style:italic;color:#969896;"># Source Nodes: [outputs], Original ATen: [aten.mm]
</span><span style="color:#323232;">        extern_kernels.mm(buf1, reinterpret_tensor(primals_2, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf2)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">(buf2, primals_3, buf1, reinterpret_tensor(primals_2, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), )
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">benchmark_compiled_module</span><span style="color:#323232;">(times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">):
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._dynamo.testing </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">rand_strided
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">print_performance
</span><span style="color:#323232;">    primals_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cuda:0&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cuda:0&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_3 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cuda:0&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    fn </span><span style="font-weight:bold;color:#a71d5d;">= lambda</span><span style="color:#323232;">: call([primals_1, primals_2, primals_3])
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">print_performance(fn, times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">times, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">repeat)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">if </span><span style="color:#323232;">__name__ </span><span style="font-weight:bold;color:#a71d5d;">== </span><span style="color:#183691;">&quot;__main__&quot;</span><span style="color:#323232;">:
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.wrapper_benchmark </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">compiled_module_main
</span><span style="color:#323232;">    compiled_module_main(</span><span style="color:#183691;">&#39;None&#39;</span><span style="color:#323232;">, benchmark_compiled_module)
</span></pre>
